# SQL-Layoff-Analysis
End-to-End Layoff Data Cleaning and EDA using SQL 
# Workforce Layoff Analysis using SQL  
### End-to-End Data Cleaning and Exploratory Data Analysis

## Overview  
This project presents a full SQL-based pipeline for cleaning and analyzing a large dataset of workforce layoffs. It is designed to showcase practical SQL skills in transforming messy data into meaningful business insights that can support strategic decisions.

## Project Objectives  
- Clean raw layoff data with SQL techniques  
- Perform exploratory data analysis to extract trends  
- Identify key metrics such as top affected industries, companies, and regions

## Tech Stack  
- SQL (Standard SQL / SQLite-compatible)  
- Dataset: Layoffs (15,000+ records)

## Project Structure  
```python
├── Data Cleaning Project.sql # SQL script to clean raw layoff data
├── EDA Project.sql # SQL script with business-focused analysis
├── README.md # Project documentation
```

## Key Metrics & Achievements  
- Cleaned and standardized over **15,000 records**  
- Applied `ROW_NUMBER()`, `CTE`, and NULL handling to remove 100% duplicates  
- Identified top **5 industries**, **5 countries**, and **peak months** for layoffs  
- Revealed trends by **company stage**, **funding round**, and **layoff count**

## Sample Insights  
- Tech and Retail sectors experienced the highest layoff volumes  
- Startups in Series A and B stages showed higher layoff vulnerability  
- Layoff spikes correlated with global market slowdowns

## How to Run  
1. Open `Data Cleaning Project.sql` in a SQL editor  
2. Execute all cleaning steps to generate a refined dataset  
3. Run `EDA Project.sql` to explore and extract insights from the clean data

## Author  
**[Sheik Faiz]**  
Aspiring Data Analyst | SQL Enthusiast  
[LinkedIn](https://www.linkedin.com/in/sheik-faiz/) 
